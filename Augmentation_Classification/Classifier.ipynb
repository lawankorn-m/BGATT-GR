{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classifier","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport numpy as npl\nfrom PLS import PLS\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom lightgbm import LGBMClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import matthews_corrcoef # average == 'macro'.\nfrom sklearn.metrics import roc_auc_score # multiclas 'ovo' average == 'macro'.\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nimport os\nfrom sklearn.metrics import auc, precision_recall_curve, roc_auc_score\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport pandas as pd\n\n# Step 1: List of specific CSV files to use from the directory\ntrain_files = [\n    'Augmentation/R0.csv',  # Replace with the actual filename\n    'Augmentation/R25.csv',  # Replace with the actual filename\n    'Augmentation/R50.csv',  # Replace with the actual filename\n    'Augmentation/R75.csv',  # Replace with the actual filename\n    'Augmentation/R100.csv'   # Replace with the actual filename\n]\n\ntest_file_path = 'Test.csv'\n\n# Load test data\ntest_df = pd.read_csv(test_file_path)\nX_test = test_df.iloc[:, 1:-1].values\ny_test = test_df.iloc[:, -1].values\n\n# Apply StandardScaler to the test data\nscaler = StandardScaler()\nX_test = scaler.fit_transform(X_test)  # Fit and transform the test set\n\n# Custom cross-validation function\ndef custom_cv(y, nr_fold):\n    skf = StratifiedKFold(n_splits=nr_fold, shuffle=True, random_state=0)\n    return skf.split(np.zeros(len(y)), y)\n\n# Define cross-validation function\ndef cv(clf, X, y, nr_fold):\n    ix = np.arange(len(y))  # Generate index array\n    allACC, allSENS, allSPEC, allMCC, allROC_AUC, allBACC, allAUC_PR = [], [], [], [], [], [], []\n    \n    for j in range(nr_fold):\n        train_ix = ((ix % nr_fold) != j)\n        test_ix = ((ix % nr_fold) == j)\n        train_X, test_X = X[train_ix], X[test_ix]\n        train_y, test_y = y[train_ix], y[test_ix]\n        \n        # Apply StandardScaler to training and testing data within each fold\n        scaler = StandardScaler()\n        train_X = scaler.fit_transform(train_X)\n        test_X = scaler.transform(test_X)\n\n        clf.fit(train_X, train_y)\n        p = clf.predict(test_X)\n        pr = clf.predict_proba(test_X)[:, 1]\n\n        TP, FP, TN, FN = 0.00001, 0.00001, 0.00001, 0.00001\n        for i in range(len(test_y)):\n            if test_y[i] == 1 and p[i] == 1:\n                TP += 1\n            elif test_y[i] == 1 and p[i] == 0:\n                FN += 1\n            elif test_y[i] == 0 and p[i] == 1:\n                FP += 1\n            elif test_y[i] == 0 and p[i] == 0:\n                TN += 1\n\n        ACC = (TP + TN) / (TP + FP + TN + FN)\n        SENS = TP / (TP + FN)\n        SPEC = TN / (TN + FP)\n        MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) != 0 else 0\n        ROC_AUC = roc_auc_score(test_y, pr)  # Renamed from 'AUC' to 'ROC_AUC'\n        F1 = TP / (TP + (0.5 * (FP + FN)))\n\n        precision, recall, _ = precision_recall_curve(test_y, pr)\n        AUC_PR = auc(recall, precision)\n\n        allACC.append(ACC)\n        allSENS.append(SENS)\n        allSPEC.append(SPEC)\n        allMCC.append(MCC)\n        allROC_AUC.append(ROC_AUC)\n        allBACC.append(F1)\n        allAUC_PR.append(AUC_PR)\n\n    return np.mean(allACC), np.mean(allSENS), np.mean(allSPEC), np.mean(allMCC), np.mean(allROC_AUC), np.mean(allBACC), np.mean(allAUC_PR)\n\n# Define test function\ndef test(clf, X, y, Xt, yt):\n    clf.fit(X, y)\n    p = clf.predict(Xt)\n    pr = clf.predict_proba(Xt)[:, 1]\n\n    TP, FP, TN, FN = 0.00001, 0.00001, 0.00001, 0.00001\n    for i in range(len(yt)):\n        if yt[i] == 1 and p[i] == 1:\n            TP += 1\n        elif yt[i] == 1 and p[i] == 0:\n            FN += 1\n        elif yt[i] == 0 and p[i] == 1:\n            FP += 1\n        elif yt[i] == 0 and p[i] == 0:\n            TN += 1\n\n    ACC = (TP + TN) / (TP + FP + TN + FN)\n    SENS = TP / (TP + FN)\n    SPEC = TN / (TN + FP)\n    MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) != 0 else 0\n    ROC_AUC = roc_auc_score(yt, pr)  # Renamed from 'AUC' to 'ROC_AUC'\n    F1 = TP / (TP + (0.5 * (FP + FN)))\n\n    precision, recall, _ = precision_recall_curve(yt, pr)\n    AUC_PR = auc(recall, precision)\n\n    return ACC, SENS, SPEC, MCC, ROC_AUC, F1, AUC_PR, TP, TN, FP, FN\n\n# Writing to CSV\noutput_file_path = \"Try_full_1000.csv\"\nwith open(output_file_path, \"a\") as file:\n    file.write(\"Prob Feature, acc, sens, spec, mcc, roc, f1, auc_pr, tp, tn, fp, fn, best param, acc, sens, spec, mcc, roc, f1, auc_pr, tp, tn, fp, fn\\n\")\n\n    # Loop through the specified files\n    for filename in train_files:\n        train_file_path = os.path.join('Train', filename)  # Assuming 'Train' is the folder path\n        train_df = pd.read_csv(train_file_path)\n        X_train = train_df.iloc[:, 1:-1].values\n        y_train = train_df.iloc[:, -1].values\n\n        # Apply StandardScaler to the training data\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        \n        # Use the filename (without the extension) as the feature name\n        feat = os.path.splitext(filename)[0]\n\n        classifiers = [\n        (\"ET\", ExtraTreesClassifier(random_state=0), {'n_estimators': [20, 50, 100, 200]}, 'n_estimators'),\n\n    ]\n\n        for clf_name, clf, param_grid, param_name in classifiers:\n            clf1 = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=custom_cv(y_train, 3), n_jobs=-1)\n            clf1.fit(X_train, y_train)\n            best_param = clf1.best_params_[param_name]\n\n            clf = clf1.best_estimator_\n            acc, sens, spec, mcc, roc_auc, f1, auc_pr = cv(clf, X_train, y_train, 3)\n            acc1, sens1, spec1, mcc1, roc_auc1, f11, auc_pr1, TP, TN, FP, FN = test(clf, X_train, y_train, X_test, y_test)\n            file.write(f\"{feat}_{clf_name},{acc},{sens},{spec},{mcc},{roc_auc},{f1},{auc_pr},{best_param},{acc1},{sens1},{spec1},{mcc1},{roc_auc1},{f11},{auc_pr1},{TP},{TN},{FP},{FN}\\n\")\nfile.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}